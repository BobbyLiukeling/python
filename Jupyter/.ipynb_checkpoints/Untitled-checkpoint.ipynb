{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright 2019 Google LLC.¶\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's disable all the warnings first\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the dependencies that will be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import collections\n",
    "import contextlib\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import six\n",
    "import sonnet as snt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过多层感知机MLP对结点和边信息进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(snt.AbstractModult):\n",
    "    def __init__(self, node_hidden_sizes=None, edge_hidden_sizes=None, \n",
    "                 name=\"graph-encoder\"):\n",
    "        '''\n",
    "        node_hidden_sizes:如果提供的是一个int型列表，即节点编码器网络的隐藏大小，最后一个元素是节点输出的大小。如果没有提供，节点特性将按原样通过。\n",
    "        Edge_hidden_sizes:如果提供的应该是一个int型的列表，边缘编码器网络的隐藏大小，最后一个元素是边缘输出的大小。如果没有提供，边缘特征将通过。\n",
    "        Name:模块名。\n",
    "        \n",
    "        应该是在MLP的基础上进行编码，\n",
    "        '''\n",
    "        super(GraphEncoder, self).__init__(name=name)\n",
    "\n",
    "        # this also handles the case of an empty list\n",
    "        self._node_hidden_sizes = node_hidden_sizes if node_hidden_sizes else None\n",
    "        self._edge_hidden_sizes = edge_hidden_sizes\n",
    "    \n",
    "    def _build(self, node_features, edge_features=None):\n",
    "        '''\n",
    "         对节点和边进行编码。\n",
    "         \n",
    "         参数:\n",
    "             node_features：[n_nodes, node_feat_dim] float tensor.\n",
    "             edge_features: if provided, should be [n_edges, edge_feat_dim] float tensor.\n",
    "\n",
    "          Returns:\n",
    "              node_outputs: [n_nodes, node_embedding_dim] float tensor, node embeddings.\n",
    "              edge_outputs: if edge_features is not None and edge_hidden_sizes is not\n",
    "                None, this is [n_edges, edge_embedding_dim] float tensor, edge\n",
    "                embeddings; otherwise just the input edge_features.\n",
    "        '''\n",
    "   \n",
    "        if self._node_hidden_sizes is None:\n",
    "          node_outputs = node_features\n",
    "        else: #默认输出层\n",
    "          node_outputs = snt.nets.MLP(\n",
    "              self._node_hidden_sizes, name='node-feature-mlp')(node_features)\n",
    "\n",
    "        if edge_features is None or self._edge_hidden_sizes is None:\n",
    "          edge_outputs = edge_features\n",
    "        else:\n",
    "          edge_outputs = snt.nets.MLP(\n",
    "              self._edge_hidden_sizes, name='edge-feature-mlp')(edge_features)\n",
    "\n",
    "        return node_outputs, edge_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传播层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_prop_once(node_states,\n",
    "                    from_idx,\n",
    "                    to_idx,\n",
    "                    message_net,\n",
    "                    aggregation_module=tf.unsorted_segment_sum,\n",
    "                    edge_features=None):\n",
    "  \"\"\"One round of propagation (message passing) in a graph.\n",
    "  图的一轮传播过程\n",
    "\n",
    "  Args:\n",
    "    node_states: [n_nodes, node_state_dim] float tensor, node state vectors, one\n",
    "      row for each node.\n",
    "    from_idx: [n_edges] int tensor, index of the from nodes.\n",
    "    to_idx: [n_edges] int tensor, index of the to nodes.\n",
    "    message_net: a network that maps concatenated edge inputs to message\n",
    "      vectors.\n",
    "    aggregation_module: a module that aggregates messages on edges to aggregated\n",
    "      messages for each node.  Should be a callable and can be called like the\n",
    "      following,\n",
    "      `aggregated_messages = aggregation_module(messages, to_idx, n_nodes)`,\n",
    "      where messages is [n_edges, edge_message_dim] tensor, to_idx is the index\n",
    "      of the to nodes, i.e. where each message should go to, and n_nodes is an\n",
    "      int which is the number of nodes to aggregate into.\n",
    "    edge_features: if provided, should be a [n_edges, edge_feature_dim] float\n",
    "      tensor, extra features for each edge.\n",
    "\n",
    "  Returns:\n",
    "    aggregated_messages: an [n_nodes, edge_message_dim] float tensor, the\n",
    "      aggregated messages, one row for each node.\n",
    "  \"\"\"\n",
    "  from_states = tf.gather(node_states, from_idx)\n",
    "  to_states = tf.gather(node_states, to_idx)\n",
    "\n",
    "  edge_inputs = [from_states, to_states]\n",
    "  if edge_features is not None:\n",
    "    edge_inputs.append(edge_features)\n",
    "\n",
    "  edge_inputs = tf.concat(edge_inputs, axis=-1)\n",
    "  messages = message_net(edge_inputs)\n",
    "\n",
    "  return aggregation_module(messages, to_idx, tf.shape(node_states)[0])\n",
    "\n",
    "\n",
    "class GraphPropLayer(snt.AbstractModule):\n",
    "  \"\"\"Implementation of a graph propagation (message passing) layer.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               node_state_dim,\n",
    "               edge_hidden_sizes,\n",
    "               node_hidden_sizes,\n",
    "               edge_net_init_scale=0.1,\n",
    "               node_update_type='residual',\n",
    "               use_reverse_direction=True,\n",
    "               reverse_dir_param_different=True,\n",
    "               layer_norm=False,\n",
    "               name='graph-net'):\n",
    "    \"\"\"Constructor.\n",
    "\n",
    "    Args:\n",
    "      node_state_dim: int, dimensionality of node states.\n",
    "      edge_hidden_sizes: list of ints, hidden sizes for the edge message\n",
    "        net, the last element in the list is the size of the message vectors.\n",
    "      node_hidden_sizes: list of ints, hidden sizes for the node update\n",
    "        net.\n",
    "      edge_net_init_scale: initialization scale for the edge networks.  This\n",
    "        is typically set to a small value such that the gradient does not blow\n",
    "        up.\n",
    "      node_update_type: type of node updates, one of {mlp, gru, residual}.\n",
    "      use_reverse_direction: set to True to also propagate messages in the\n",
    "        reverse direction.\n",
    "      reverse_dir_param_different: set to True to have the messages computed\n",
    "        using a different set of parameters than for the forward direction.\n",
    "      layer_norm: set to True to use layer normalization in a few places.\n",
    "      name: name of this module.\n",
    "    \"\"\"\n",
    "    super(GraphPropLayer, self).__init__(name=name)\n",
    "\n",
    "    self._node_state_dim = node_state_dim\n",
    "    self._edge_hidden_sizes = edge_hidden_sizes[:]\n",
    "\n",
    "    # output size is node_state_dim\n",
    "    self._node_hidden_sizes = node_hidden_sizes[:] + [node_state_dim]\n",
    "    self._edge_net_init_scale = edge_net_init_scale\n",
    "    self._node_update_type = node_update_type\n",
    "\n",
    "    self._use_reverse_direction = use_reverse_direction\n",
    "    self._reverse_dir_param_different = reverse_dir_param_different\n",
    "\n",
    "    self._layer_norm = layer_norm\n",
    "\n",
    "  def _compute_aggregated_messages(\n",
    "      self, node_states, from_idx, to_idx, edge_features=None):\n",
    "    \"\"\"Compute aggregated messages for each node.\n",
    "\n",
    "    Args:\n",
    "      node_states: [n_nodes, input_node_state_dim] float tensor, node states.\n",
    "      from_idx: [n_edges] int tensor, from node indices for each edge.\n",
    "      to_idx: [n_edges] int tensor, to node indices for each edge.\n",
    "      edge_features: if not None, should be [n_edges, edge_embedding_dim]\n",
    "        tensor, edge features.\n",
    "\n",
    "    Returns:\n",
    "      aggregated_messages: [n_nodes, aggregated_message_dim] float tensor, the\n",
    "        aggregated messages for each node.\n",
    "    \"\"\"\n",
    "    self._message_net = snt.nets.MLP(\n",
    "        self._edge_hidden_sizes,\n",
    "        initializers={\n",
    "            'w': tf.variance_scaling_initializer(\n",
    "                scale=self._edge_net_init_scale),\n",
    "            'b': tf.zeros_initializer()},\n",
    "        name='message-mlp')\n",
    "\n",
    "    aggregated_messages = graph_prop_once(\n",
    "        node_states,\n",
    "        from_idx,\n",
    "        to_idx,\n",
    "        self._message_net,\n",
    "        aggregation_module=tf.unsorted_segment_sum,\n",
    "        edge_features=edge_features)\n",
    "\n",
    "    # optionally compute message vectors in the reverse direction\n",
    "    if self._use_reverse_direction:\n",
    "      if self._reverse_dir_param_different:\n",
    "        self._reverse_message_net = snt.nets.MLP(\n",
    "            self._edge_hidden_sizes,\n",
    "            initializers={\n",
    "                'w': tf.variance_scaling_initializer(\n",
    "                    scale=self._edge_net_init_scale),\n",
    "                'b': tf.zeros_initializer()},\n",
    "            name='reverse-message-mlp')\n",
    "      else:\n",
    "        self._reverse_message_net = self._message_net\n",
    "\n",
    "      reverse_aggregated_messages = graph_prop_once(\n",
    "          node_states,\n",
    "          to_idx,\n",
    "          from_idx,\n",
    "          self._reverse_message_net,\n",
    "          aggregation_module=tf.unsorted_segment_sum,\n",
    "          edge_features=edge_features)\n",
    "\n",
    "      aggregated_messages += reverse_aggregated_messages\n",
    "\n",
    "    if self._layer_norm:\n",
    "      aggregated_messages = snt.LayerNorm()(aggregated_messages)\n",
    "\n",
    "    return aggregated_messages\n",
    "\n",
    "  def _compute_node_update(self,\n",
    "                           node_states,\n",
    "                           node_state_inputs,\n",
    "                           node_features=None):\n",
    "    \"\"\"Compute node updates.\n",
    "\n",
    "    Args:\n",
    "      node_states: [n_nodes, node_state_dim] float tensor, the input node\n",
    "        states.\n",
    "      node_state_inputs: a list of tensors used to compute node updates.  Each\n",
    "        element tensor should have shape [n_nodes, feat_dim], where feat_dim can\n",
    "        be different.  These tensors will be concatenated along the feature\n",
    "        dimension.\n",
    "      node_features: extra node features if provided, should be of size\n",
    "        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement\n",
    "        different types of skip connections.\n",
    "\n",
    "    Returns:\n",
    "      new_node_states: [n_nodes, node_state_dim] float tensor, the new node\n",
    "        state tensor.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if node update type is not supported.\n",
    "    \"\"\"\n",
    "    if self._node_update_type in ('mlp', 'residual'):\n",
    "      node_state_inputs.append(node_states)\n",
    "    if node_features is not None:\n",
    "      node_state_inputs.append(node_features)\n",
    "\n",
    "    if len(node_state_inputs) == 1:\n",
    "      node_state_inputs = node_state_inputs[0]\n",
    "    else:\n",
    "      node_state_inputs = tf.concat(node_state_inputs, axis=-1)\n",
    "\n",
    "    if self._node_update_type == 'gru':\n",
    "      _, new_node_states = snt.GRU(self._node_state_dim)(\n",
    "          node_state_inputs, node_states)\n",
    "      return new_node_states\n",
    "    else:\n",
    "      mlp_output = snt.nets.MLP(\n",
    "          self._node_hidden_sizes, name='node-mlp')(node_state_inputs)\n",
    "      if self._layer_norm:\n",
    "        mlp_output = snt.LayerNorm()(mlp_output)\n",
    "      if self._node_update_type == 'mlp':\n",
    "        return mlp_output\n",
    "      elif self._node_update_type == 'residual':\n",
    "        return node_states + mlp_output\n",
    "      else:\n",
    "        raise ValueError('Unknown node update type %s' % self._node_update_type)\n",
    "\n",
    "  def _build(self,\n",
    "             node_states,\n",
    "             from_idx,\n",
    "             to_idx,\n",
    "             edge_features=None,\n",
    "             node_features=None):\n",
    "    \"\"\"Run one propagation step.\n",
    "\n",
    "    Args:\n",
    "      node_states: [n_nodes, input_node_state_dim] float tensor, node states.\n",
    "      from_idx: [n_edges] int tensor, from node indices for each edge.\n",
    "      to_idx: [n_edges] int tensor, to node indices for each edge.\n",
    "      edge_features: if not None, should be [n_edges, edge_embedding_dim]\n",
    "        tensor, edge features.\n",
    "      node_features: extra node features if provided, should be of size\n",
    "        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement\n",
    "        different types of skip connections.\n",
    "\n",
    "    Returns:\n",
    "      node_states: [n_nodes, node_state_dim] float tensor, new node states.\n",
    "    \"\"\"\n",
    "    aggregated_messages = self._compute_aggregated_messages(\n",
    "        node_states, from_idx, to_idx, edge_features=edge_features)\n",
    "\n",
    "    return self._compute_node_update(node_states,\n",
    "                                     [aggregated_messages],\n",
    "                                     node_features=node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
